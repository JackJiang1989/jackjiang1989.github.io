Yann LeCun says there is no such thing as general intelligence
Human intelligence is super-specialized for the physical world, and our feeling of generality is an illusion
We only seem general because we can't imagine the problems we're blind to
"the concept is complete BS"



Demis Hassabis
Yann is just plain incorrect here, he’s confusing general intelligence with universal intelligence.
Brains are the most exquis​ite and complex phenomena we know of in the universe (so far), and they are in fact extremely general.
Obviously one can’t circumvent the no free lunch theorem so in a practical and finite system there always has to be some degree of specialisation around the ​target distribution that is being learnt.
But the point about generality is that in theory, in the Turing Machine sense​, the architecture of ​s​uch a general system is capable of learning anything computable given enough time and memory​ (and data), and the human brain (and AI foundation models) are approximate Turing Machines.
Finally, with ​regards to ​Yann's comments about chess players, it’s amazing that humans could have invented chess ​in the first place (and all the other ​a​spects ​o​f modern civilization ​from science to 747s!) let alone get as brilliant at it as someone like Magnus. He may not be ​strictly optimal (after all he has finite memory and limited time to make a decision) but it’s incredible what he and we can do with our brains given they were evolved for hunter gathering.


Yann LeCun
I think the disagreement is largely one of vocabulary.
I object to the use of "general" to designate "human level" because humans are extremely specialized.
You may disagree that the human mind is specialized, but it really is. It's not just a question of theoretical power but also a question of practical efficiency.
Clearly, a properly trained human brain with an infinite supply of pens and paper is Turing complete.
But for the vast majority of computational problems, it's horribly inefficient, which makes it highly suboptimal under bounded resources (like playing a chess game). 
Let me give an analogy: in theory, a 2-layer neural net can approximate any function as close as you want. In practice, almost every interesting function requires a impractically large number of units in the hidden layer. So we use multi-layer networks (that's actually the raison d'être for deep learning).
Here is another argument: the optic nerve has 1 million nerve fiber. Let's make the simplifying assumption that the signals are binary. A vision task is therefore a boolean function from 1E6 bits to 1 bit.
Among all the possible such functions, what proportion are implementable by the brain?
The answer is: an infinitesimal proportion.
The number of boolean functions of 1 million bits is 2^(2^1E6), which an unimaginably large number, about 2^(1E301030) or 10^(3x1E301029).
Now, assuming that the human brain has 1E11 neurons, and perhaps 1E14 synapses, each represented on, say, 32 bits. The total number of bits to specify the entire connectome is at most 3.2E15. This means the total number of boolean function representable (computable) by the entire human brain is at most 2^(3.2E15).
This is a teeny-tiny number compared to 2^(1E301030).
Not only are we not general, we are *ridiculously* specialized.
The space of possible function is vast. 
We don't realize it because most of those functions are unfathomably complicated to and us and look completely random.
I love this quote from Albert Einstein: "the most incomprehensible thing about the world is that the world is comprehensible"
It's pretty incredible that among all the random ways the world could be organized, we can actually find a way to understand a tiny part of it.
The part we don't understand, we call entropy.
Most of the information content of the universe is entropy: things we simply cannot understand with our feeble minds and choose to ignore.